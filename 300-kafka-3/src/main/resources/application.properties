#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.group-id=myGroup
#server.port=9090
spring.application.name=lyy-kafka-2
spring.kafka.bootstrap-servers=192.168.0.215:9092,192.168.0.215:9093,192.168.0.215:9094
spring.kafka.consumer.group-id=${spring.application.name}
spring.kafka.producer.properties.partitioner.class=cn.liuyiyou.springboot.kafka.partition.MyPartitioner
spring.kafka.producer.properties.interceptor.classes=cn.liuyiyou.springboot.kafka.interceptor.MyProducerInterceptor
#这意味着leader需要等待所有备份都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的保证。
spring.kafka.producer.acks=all
#关闭自动提交offset
spring.kafka.consumer.enable-auto-commit=false
# Producer factory does not support transactions
#spring.kafka.producer.transaction-id-prefix=transaction
